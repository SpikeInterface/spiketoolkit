{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSTPROCESSING MODULE\n",
    "\n",
    "This notebook shows how to use the spiketoolkit.postprocessing module to:\n",
    "- compute spike waveforms\n",
    "- compute unit templates\n",
    "- compute largest channel id\n",
    "- compute pca scores\n",
    "- export sorted data to phy to curate the results\n",
    "- reload the curated data and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeextractors as se\n",
    "import spiketoolkit as st\n",
    "import spikewidgets as sw\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.signal as ss\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create toy example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording, sorting = se.example_datasets.toy_example(num_channels=4, duration=30)\n",
    "#recording = se.MEArecRecordingExtractor('/home/alessiob/Documents/Codes/MEArec/data/recordings/recordings_20cells_Neuronexus-32_10.0_10.0uV_20-02-2019:15:11.h5')\n",
    "#sorting = se.MEArecSortingExtractor('/home/alessiob/Documents/Codes/MEArec/data/recordings/recordings_20cells_Neuronexus-32_10.0_10.0uV_20-02-2019:15:11.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the `sorting` is the output of a spike sorter, the `postprocessing` module allows to extract all relevant information from the paired recording-sorting.\n",
    "\n",
    "### Extracting waveforms\n",
    "\n",
    "Waveforms are extracted with the `get_unit_waveforms` function by extracting snippets of the recordings when spikes are detected. When waveforms are extracted, the can be loaded in the `SortingExtractor` object as features. The ms before and after the spike event can be chosen. Waveforms are returned as a list of np.arrays (n_spikes, n_channels, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = st.postprocessing.get_unit_waveforms(recording, sorting, ms_before=1, ms_after=2, \n",
    "                                        save_as_features=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `waveforms` is a unit spike feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.get_unit_spike_feature_names()\n",
    "wf[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting waveforms of units 0,1,2 on channel 0\n",
    "plt.figure()\n",
    "_ = plt.plot(wf[0][:, 0, :].T, color='k', lw=0.3)\n",
    "_ = plt.plot(wf[1][:, 0, :].T, color='r', lw=0.3)\n",
    "_ = plt.plot(wf[2][:, 0, :].T, color='b', lw=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the a certain property (e.g. `group`) is present in the RecordingExtractor, the waveforms can be extracted only on the channels with that property using the `grouping_property` and `compute_property_from_recording` arguments. For example, if channel [0,1] are in group 0 and channel [2,3] are in group 2, then if the peak of the waveforms is in channel [0,1] it will be assigned to group 0 and will have 2 channels and the same for group 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_groups = [[0, 1], [2, 3]]\n",
    "for ch in recording.get_channel_ids():\n",
    "    for gr, channel_group in enumerate(channel_groups):\n",
    "        if ch in channel_group:\n",
    "            recording.set_channel_property(ch, 'group', gr)\n",
    "print(recording.get_channel_property(0, 'group'), recording.get_channel_property(2, 'group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_by_group = st.postprocessing.get_unit_waveforms(recording, sorting, ms_before=1, ms_after=2, \n",
    "                                                   save_as_features=False, verbose=True,\n",
    "                                                   grouping_property='group', \n",
    "                                                   compute_property_from_recording=True)\n",
    "\n",
    "# now waveforms will only have 2 channels\n",
    "print(wf_by_group[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates (EAP)\n",
    "\n",
    "Similarly to waveforms, templates - average waveforms - can be easily extracted using the `get_unit_templates`. When spike trains have numerous spikes, you can set the `max_num_waveforms` to be extracted. If waveforms have already been computd and stored as `features`, those will be used. Templates can be saved as unit properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = st.postprocessing.get_unit_template(recording, sorting, max_num_waveforms=200,\n",
    "                                              save_as_property=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.get_unit_property_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting templates of units 0,1,2 on all four channels\n",
    "plt.figure()\n",
    "_ = plt.plot(templates[0].T, color='k')\n",
    "_ = plt.plot(templates[1].T, color='r')\n",
    "_ = plt.plot(templates[2].T, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum channel\n",
    "\n",
    "In the same way, one can get the ecording channel with the maximum amplitude and save it as a property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chan = st.postprocessing.get_unit_max_channel(recording, sorting, save_as_property=True, verbose=True)\n",
    "print(max_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.get_unit_property_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA scores\n",
    "\n",
    "For some applications, for example validating the spike sorting output, PCA scores can be computed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scores = st.postprocessing.compute_pca_scores(recording, sorting, n_comp=3, verbose=True)\n",
    "\n",
    "for pc in pca_scores:\n",
    "    print(pc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(pca_scores[0][:,0], pca_scores[0][:,1], 'r*')\n",
    "ax.plot(pca_scores[2][:,0], pca_scores[2][:,1], 'b*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA scores can be also computed electrode-wise. In the previous example, PCA was applied to the concatenation of the waveforms over channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scores_by_electrode = st.postprocessing.compute_pca_scores(recording, sorting, n_comp=3, by_electrode=True)\n",
    "\n",
    "for pc in pca_scores_by_electrode:\n",
    "    print(pc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, as expected, 3 principal components are extracted for each electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(pca_scores_by_electrode[0][:, 0, 0], pca_scores_by_electrode[0][:, 1, 0], 'r*')\n",
    "ax.plot(pca_scores_by_electrode[2][:, 0, 0], pca_scores_by_electrode[2][:, 1, 1], 'b*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data curation using Phy\n",
    "\n",
    "Finally, it is common to visualize and manually curate the data after spike sorting.\n",
    "In order to do so, we interface wiht the Phy (https://phy-contrib.readthedocs.io/en/latest/template-gui/).\n",
    "\n",
    "First, we need to export the data to the phy format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording, sorting, output_folder='phy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!phy template-gui phy/params.py --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, in phy, we manually merged to units. We can load back the curated data using the `PhysortingExtractor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_curated = se.PhySortingExtractor('phy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before curation: ', len(sorting.get_unit_ids()))\n",
    "print('After curation: ', len(sorting_curated.get_unit_ids()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save curated recordings\n",
    "\n",
    "The curated recordings can be either saved in any other format, or the PhySortingExtractor can be used reload the data from the phy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.MdaSortingExtractor.write_sorting(sorting=sorting_curated, save_path='curated_results.mda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
