{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSTPROCESSING MODULE\n",
    "\n",
    "This notebook shows how to use the spiketoolkit.postprocessing module to:\n",
    "1. compute spike waveforms\n",
    "2. compute unit templates\n",
    "3. compute unit maximum channel\n",
    "4. compute pca scores\n",
    "5. export sorted data to phy to curate the results\n",
    "6. save curated sorting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeextractors as se\n",
    "import spiketoolkit as st\n",
    "import spikewidgets as sw\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.signal as ss\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create toy example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording, sorting = se.example_datasets.toy_example(num_channels=4, duration=30, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the `sorting` is the output of a spike sorter, the `postprocessing` module allows to extract all relevant information from the paired recording-sorting.\n",
    "\n",
    "## 1) Compute spike waveforms\n",
    "\n",
    "Waveforms are extracted with the `get_units_waveforms` function by extracting snippets of the recordings when spikes are detected. When waveforms are extracted, the can be loaded in the `SortingExtractor` object as features. The ms before and after the spike event can be chosen. Waveforms are returned as a list of np.arrays (n_spikes, n_channels, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = st.postprocessing.get_units_waveforms(recording, sorting, ms_before=1, ms_after=2, \n",
    "                                        save_as_features=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `waveforms` is a unit spike feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.get_unit_spike_feature_names()\n",
    "wf[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting waveforms of units 0,1,2 on channel 0\n",
    "plt.figure()\n",
    "plt.plot(wf[0][:, 0, :].T, color='k', lw=0.3)\n",
    "plt.plot(wf[1][:, 0, :].T, color='r', lw=0.3)\n",
    "plt.plot(wf[2][:, 0, :].T, color='b', lw=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the a certain property (e.g. `group`) is present in the RecordingExtractor, the waveforms can be extracted only on the channels with that property using the `grouping_property` and `compute_property_from_recording` arguments. For example, if channel [0,1] are in group 0 and channel [2,3] are in group 2, then if the peak of the waveforms is in channel [0,1] it will be assigned to group 0 and will have 2 channels and the same for group 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_groups = [[0, 1], [2, 3]]\n",
    "for ch in recording.get_channel_ids():\n",
    "    for gr, channel_group in enumerate(channel_groups):\n",
    "        if ch in channel_group:\n",
    "            recording.set_channel_property(ch, 'group', gr)\n",
    "print(recording.get_channel_property(0, 'group'), recording.get_channel_property(2, 'group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_by_group = st.postprocessing.get_units_waveforms(recording, sorting, ms_before=1, ms_after=2, \n",
    "                                                   save_as_features=False, verbose=True,\n",
    "                                                   grouping_property='group', \n",
    "                                                   compute_property_from_recording=True)\n",
    "\n",
    "# now waveforms will only have 2 channels\n",
    "print(wf_by_group[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Compute unit templates (EAP)\n",
    "\n",
    "Similarly to waveforms, templates - average waveforms - can be easily extracted using the `get_units_templatess`. When spike trains have numerous spikes, you can set the `max_num_waveforms` to be extracted. If waveforms have already been computd and stored as `features`, those will be used. Templates can be saved as unit properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = st.postprocessing.get_units_templates(recording, sorting, max_num_waveforms=200,\n",
    "                                              save_as_property=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.get_unit_property_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting templates of units 0,1,2 on all four channels\n",
    "plt.figure()\n",
    "_ = plt.plot(templates[0].T, color='k')\n",
    "_ = plt.plot(templates[1].T, color='r')\n",
    "_ = plt.plot(templates[2].T, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Compute unit maximum channel\n",
    "\n",
    "In the same way, one can get the ecording channel with the maximum amplitude and save it as a property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chan = st.postprocessing.get_units_max_channels(recording, sorting, save_as_property=True, verbose=True)\n",
    "print(max_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.get_unit_property_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Compute pca scores\n",
    "\n",
    "For some applications, for example validating the spike sorting output, PCA scores can be computed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scores = st.postprocessing.compute_units_pca_scores(recording, sorting, n_comp=3, verbose=True)\n",
    "\n",
    "for pc in pca_scores:\n",
    "    print(pc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(pca_scores[0][:,0], pca_scores[0][:,1], 'r*')\n",
    "ax.plot(pca_scores[2][:,0], pca_scores[2][:,1], 'b*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA scores can be also computed electrode-wise. In the previous example, PCA was applied to the concatenation of the waveforms over channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scores_by_electrode = st.postprocessing.compute_units_pca_scores(recording, sorting, n_comp=3, by_electrode=True)\n",
    "\n",
    "for pc in pca_scores_by_electrode:\n",
    "    print(pc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, as expected, 3 principal components are extracted for each electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(pca_scores_by_electrode[0][:, 0, 0], pca_scores_by_electrode[0][:, 1, 0], 'r*')\n",
    "ax.plot(pca_scores_by_electrode[2][:, 0, 0], pca_scores_by_electrode[2][:, 1, 1], 'b*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Automatically Curate the sorted result\n",
    "\n",
    "Before manually curating your dataset (which can be time intensive on large-scale recordings) it may be a good idea to perform\n",
    "some automated curation of the sorted result.\n",
    "\n",
    "Below is an example of two simple, automatic curation methods you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_list = st.validation.qualitymetrics.compute_unit_SNR(recording, sorting)\n",
    "print(snr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_sorting1 = st.postprocessing.threshold_min_num_spikes(sorting=sorting, min_num_spike_threshold=70)\n",
    "print(\"Unit spike train lengths uncurated: \" + str([len(spike_train) for spike_train in [sorting.get_unit_spike_train(unit_id) for unit_id in sorting.get_unit_ids()]]))\n",
    "print(\"Unit spike train lengths curated: \" + str([len(spike_train) for spike_train in [curated_sorting1.get_unit_spike_train(unit_id) for unit_id in curated_sorting1.get_unit_ids()]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold_min_num_spikes automatically rejects any units with number of spikes lower than the given threshold. It returns a sorting extractor without those units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_sorting2 = st.postprocessing.threshold_min_SNR(recording=recording, sorting=curated_sorting1, \n",
    "                                                       min_SNR_threshold=6.0)\n",
    "print(\"Unit SNRs uncurated: \" + str(st.validation.qualitymetrics.compute_unit_SNR(recording, curated_sorting1)))\n",
    "print(\"Unit SNRs curated: \" + str(st.validation.qualitymetrics.compute_unit_SNR(recording, curated_sorting2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold_min_SNR automatically rejects any units with SNR lower than the given threshold. It returns a sorting extractor without those units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Export sorted data to phy to manually curate the results\n",
    "\n",
    "Finally, it is common to visualize and manually curate the data after spike sorting.\n",
    "In order to do so, we interface wiht the Phy (https://phy-contrib.readthedocs.io/en/latest/template-gui/).\n",
    "\n",
    "First, we need to export the data to the phy format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording, curated_sorting2, output_folder='phy', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!phy template-gui phy/params.py --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, in phy, we manually merged to units. We can load back the curated data using the `PhysortingExtractor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_sorting3 = se.PhySortingExtractor('phy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before manual curation: ', len(curated_sorting2.get_unit_ids()))\n",
    "print('After manual curation: ', len(curated_sorting3.get_unit_ids()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Save curated sorting output\n",
    "\n",
    "The curated recordings can be either saved in any other format, or the PhySortingExtractor can be used reload the data from the phy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.MdaSortingExtractor.write_sorting(sorting=curated_sorting3, save_path='curated_results.mda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spikeinterface]",
   "language": "python",
   "name": "conda-env-spikeinterface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
