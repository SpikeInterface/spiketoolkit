{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING MODULE\n",
    "\n",
    "This notebook shows how to use the spiketoolkit.preprocessing module to:\n",
    "- apply filters\n",
    "- change reference\n",
    "- remove stimulation artifacts\n",
    "- compute LFP and MUA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeextractors as se\n",
    "import spiketoolkit as st\n",
    "import spikewidgets as sw\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.signal as ss\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create toy example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording, sorting = se.example_datasets.toy_example(num_channels=4, duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Now apply a bandpass filter and a notch filter (separately) to the recording extractor. Filters are also RecordingExtractor objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_bp = st.preprocessing.bandpass_filter(recording, freq_min=300, freq_max=6000)\n",
    "recording_notch = st.preprocessing.notch_filter(recording, freq=1000, q=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the power spectrum of non-filtered, bandpass filtered, and notch filtered recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_raw, p_raw = ss.welch(recording.get_traces(), fs=recording.get_sampling_frequency())\n",
    "f_bp, p_bp = ss.welch(recording_bp.get_traces(), fs=recording.get_sampling_frequency())\n",
    "f_notch, p_notch = ss.welch(recording_notch.get_traces(), fs=recording.get_sampling_frequency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.semilogy(f_raw, p_raw[0], f_bp, p_bp[0], f_notch, p_notch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting LFP and MUA\n",
    "\n",
    "Local field potentials (LFP) are low frequency components of the extracellular recordings.\n",
    "Multi-unit activity (MUA) are rectified and low-pass filtered recordings showing the diffuse spiking activity.\n",
    "\n",
    "In `spiketoolkit`, LFP and MUA can be extracted combining the `bandpass_filter`, `rectify` and `resample` functions. In this example LFP and MUA are resampled at 1000 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_lfp = st.preprocessing.bandpass_filter(recording, freq_min=1, freq_max=300)\n",
    "recording_lfp = st.preprocessing.resample(recording_lfp, 1000)\n",
    "recording_mua = st.preprocessing.resample(st.preprocessing.rectify(recording), 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The toy example data are only contain high frequency components, but these lines of code will work on experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the reference\n",
    "\n",
    "In many cases, before spike sorting, it is wise to re-reference the signals to reduce the common-mode noise from the recordings.\n",
    "\n",
    "To re-reference in `spiketoolkit` you can use the `common_reference` function. Both common average reference (CAR) and common median reference (CMR) can be applied. Moreover, the average/median can be computed on different groups. Single channels can also be used as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_car = st.preprocessing.common_reference(recording, reference='average')\n",
    "recording_cmr = st.preprocessing.common_reference(recording, reference='median')\n",
    "recording_single = st.preprocessing.common_reference(recording, reference='single', ref_channel=0)\n",
    "recording_single_groups = st.preprocessing.common_reference(recording, reference='single', groups=[[0,1], [2,3]], \n",
    "                                                            ref_channel=[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.plot(recording_car.get_traces()[0])\n",
    "_ = plt.plot(recording_cmr.get_traces()[0])\n",
    "plt.figure()\n",
    "_ = plt.plot(recording_single_groups.get_traces()[1]) # not zero\n",
    "_ = plt.plot(recording_single_groups.get_traces()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stimulation artifacts\n",
    "\n",
    "In some applications, electrodes are used to electrically stimulate the tissue, generating a large artifact.\n",
    "In `spiketoolkit`, the artifact can be zeroed-out using the `remove_artifact` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy stimulation triggers\n",
    "stimulation_trigger_frames = np.array([100000, 500000, 700000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large ms_before and s_after are used for plotting only\n",
    "recording_rmartifact = st.preprocessing.remove_artifacts(recording, \n",
    "                                                         triggers=stimulation_trigger_frames, \n",
    "                                                         ms_before=100, ms_after=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.plot(recording.get_traces()[0])\n",
    "_ = plt.plot(recording_rmartifact.get_traces()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the proper preprocessing step, you are ready to run spike sorting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
